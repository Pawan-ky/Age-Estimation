{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Age Classification of Faces"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Refer to my **[article on Towards Data Science](https://towardsdatascience.com/age-detection-using-facial-images-traditional-machine-learning-vs-deep-learning-2437b2feeab2)** for a complete walkthrough of this project, and links to all the source code notebooks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Contents:\n",
    "- [Setup](#Setup)\n",
    "- [Age Detection on Image](#Age-Detection-on-Image)\n",
    "- [Age Detection on Video](#Age-Detection-on-Video)\n",
    "    - [Age Detection on Live Webcam Video](#Age-Detection-on-Live-Webcam-Video)\n",
    "    - [Age Detection on a Video File](#Age-Detection-on-a-Video-File)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "# Please refer to requirements.txt for a full list of all libraries and their versions used in this project.\n",
    "\n",
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "from tensorflow.keras.models import load_model\n",
    "import time\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the trained CNN model for age classification, and\n",
    "# defining a list of age-ranges as defined in the model.\n",
    "\n",
    "model = load_model(\"age_detect_cnn_model.h5\")\n",
    "age_ranges = ['1-2', '3-9', '10-20', '21-27', '28-45', '46-65', '66-116']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Face detection** in Python can be easily implemented using the ***OpenCV* library** (read about it [here](https://medium.com/analytics-vidhya/how-to-build-a-face-detection-model-in-python-8dc9cecadfe9)). In this notebook, I will be using the [Haar Cascades](https://docs.opencv.org/3.3.0/d7/d8b/tutorial_py_face_detection.html) classifier to detect faces. The pre-trained model file in XML format is already a part of the *OpenCV* package, or can be downloaded from [here](https://github.com/opencv/opencv/blob/master/data/haarcascades/haarcascade_frontalface_default.xml)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the Haar Cascades classifier XML file.\n",
    "\n",
    "face_cascade = cv2.CascadeClassifier(\"haarcascade_frontalface_default.xml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining a function to shrink the detected face region by a scale for better prediction in the model.\n",
    "\n",
    "def shrink_face_roi(x, y, w, h, scale=0.9):\n",
    "    wh_multiplier = (1-scale)/2\n",
    "    x_new = int(x + (w * wh_multiplier))\n",
    "    y_new = int(y + (h * wh_multiplier))\n",
    "    w_new = int(w * scale)\n",
    "    h_new = int(h * scale)\n",
    "    return (x_new, y_new, w_new, h_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining a function to create the predicted age overlay on the image by centering the text.\n",
    "\n",
    "def create_age_text(img, text, pct_text, x, y, w, h):\n",
    "\n",
    "    # Defining font, scales and thickness.\n",
    "    fontFace = cv2.FONT_HERSHEY_SIMPLEX\n",
    "    text_scale = 1.2\n",
    "    yrsold_scale = 0.7\n",
    "    pct_text_scale = 0.65\n",
    "\n",
    "    # Getting width, height and baseline of age text and \"years old\".\n",
    "    (text_width, text_height), text_bsln = cv2.getTextSize(text, fontFace=fontFace, fontScale=text_scale, thickness=2)\n",
    "    (yrsold_width, yrsold_height), yrsold_bsln = cv2.getTextSize(\"years old\", fontFace=fontFace, fontScale=yrsold_scale, thickness=1)\n",
    "    (pct_text_width, pct_text_height), pct_text_bsln = cv2.getTextSize(pct_text, fontFace=fontFace, fontScale=pct_text_scale, thickness=1)\n",
    "\n",
    "    # Calculating center point coordinates of text background rectangle.\n",
    "    x_center = x + (w/2)\n",
    "    y_text_center = y + h + 20\n",
    "    y_yrsold_center = y + h + 48\n",
    "    y_pct_text_center = y + h + 75\n",
    "\n",
    "    # Calculating bottom left corner coordinates of text based on text size and center point of background rectangle calculated above.\n",
    "    x_text_org = int(round(x_center - (text_width / 2)))\n",
    "    y_text_org = int(round(y_text_center + (text_height / 2)))\n",
    "    x_yrsold_org = int(round(x_center - (yrsold_width / 2)))\n",
    "    y_yrsold_org = int(round(y_yrsold_center + (yrsold_height / 2)))\n",
    "    x_pct_text_org = int(round(x_center - (pct_text_width / 2)))\n",
    "    y_pct_text_org = int(round(y_pct_text_center + (pct_text_height / 2)))\n",
    "\n",
    "    face_age_background = cv2.rectangle(img, (x-1, y+h), (x+w+1, y+h+94), (0, 100, 0), cv2.FILLED)\n",
    "    face_age_text = cv2.putText(img, text, org=(x_text_org, y_text_org), fontFace=fontFace, fontScale=text_scale, thickness=2, color=(255, 255, 255), lineType=cv2.LINE_AA)\n",
    "    yrsold_text = cv2.putText(img, \"years old\", org=(x_yrsold_org, y_yrsold_org), fontFace=fontFace, fontScale=yrsold_scale, thickness=1, color=(255, 255, 255), lineType=cv2.LINE_AA)\n",
    "    pct_age_text = cv2.putText(img, pct_text, org=(x_pct_text_org, y_pct_text_org), fontFace=fontFace, fontScale=pct_text_scale, thickness=1, color=(255, 255, 255), lineType=cv2.LINE_AA)\n",
    "\n",
    "    return (face_age_background, face_age_text, yrsold_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining a function to find faces in an image and then classify each found face into age-ranges defined above.\n",
    "\n",
    "def classify_age(img):\n",
    "\n",
    "    # Making a copy of the image for overlay of ages and making a grayscale copy for passing to the loaded model for age classification.\n",
    "    img_copy = np.copy(img)\n",
    "    img_gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Detecting faces in the image using the face_cascade loaded above and storing their coordinates into a list.\n",
    "    faces = face_cascade.detectMultiScale(img_copy, scaleFactor=1.2, minNeighbors=6, minSize=(100, 100))\n",
    "    print(faces)\n",
    "    print(f\"{len(faces)} faces found.\")\n",
    "\n",
    "    # Looping through each face found in the image.\n",
    "    for i, (x, y, w, h) in enumerate(faces):\n",
    "\n",
    "        # Drawing a rectangle around the found face.\n",
    "        face_rect = cv2.rectangle(img_copy, (x, y), (x+w, y+h), (0, 100, 0), thickness=2)\n",
    "        \n",
    "        # Predicting the age of the found face using the model loaded above.\n",
    "        x2, y2, w2, h2 = shrink_face_roi(x, y, w, h)\n",
    "        face_roi = img_gray[y2:y2+h2, x2:x2+w2]\n",
    "        face_roi = cv2.resize(face_roi, (200, 200))\n",
    "        face_roi = face_roi.reshape(-1, 200, 200, 1)\n",
    "        face_age = age_ranges[np.argmax(model.predict(face_roi))]\n",
    "        face_age_pct = round(np.max(model.predict(face_roi))*100, 2)\n",
    "        print(face_age_pct)\n",
    "        \n",
    "        # Calling the above defined function to create the predicted age overlay on the image.\n",
    "     #   face_age_background, face_age_text, yrsold_text = create_age_text(img_copy, face_age, face_age_pct, x, y, w, h)\n",
    "        # print(f\"Age prediction for face {i+1} : {face_age} years old\")\n",
    "\n",
    "    return face_age,face_age_pct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_age(img):\n",
    "    # Making a copy of the image for overlay of ages and making a grayscale copy for passing to the loaded model for\n",
    "    # age classification.\n",
    "    img_copy = np.copy(img)\n",
    "    img_gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Detecting faces in the image using the face_cascade loaded above and storing their coordinates into a list.\n",
    "    faces = face_cascade.detectMultiScale(img_copy, scaleFactor=1.2, minNeighbors=6, minSize=(100, 100))\n",
    "    # print(f\"{len(faces)} faces found.\")\n",
    "\n",
    "    if len(faces) < 0:\n",
    "        print('No Face Found Please try again')\n",
    "        return 'No Face'\n",
    "    elif len(faces) > 1:\n",
    "        print('More than 1 face found')\n",
    "        return 'More faces'\n",
    "    else:\n",
    "\n",
    "        # Looping through each face found in the image.\n",
    "        for i, (x, y, w, h) in enumerate(faces):\n",
    "            # Drawing a rectangle around the found face.\n",
    "            face_rect = cv2.rectangle(img_copy, (x, y), (x + w, y + h), (0, 100, 0), thickness=2)\n",
    "\n",
    "            # Predicting the age of the found face using the model loaded above.\n",
    "            x2, y2, w2, h2 = shrink_face_roi(x, y, w, h)\n",
    "            face_roi = img_gray[y2:y2 + h2, x2:x2 + w2]\n",
    "            face_roi = cv2.resize(face_roi, (200, 200))\n",
    "            face_roi = face_roi.reshape(-1, 200, 200, 1)\n",
    "            face_age = age_ranges[np.argmax(model.predict(face_roi))]\n",
    "            face_age_pct = round(np.max(model.predict(face_roi)) * 100, 2)  # estimation confidence\n",
    "\n",
    "    return face_age, face_age_pct  # returns age range and confidence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining a function to return the image filepath with a new filename.\n",
    "# If INPUT filepath is \"my_folder1/my_folder2/my_image.jpg\", OUTPUT filepath will be \"my_folder1/my_folder2/my_image_WITH_AGE.jpg\"\n",
    "\n",
    "def new_img_name(org_img_path):\n",
    "    img_path, img_name_ext = os.path.split(org_img_path)\n",
    "    img_name, img_ext = os.path.splitext(img_name_ext)\n",
    "\n",
    "    new_img_name_ext = img_name+\"_WITH_AGE\"+img_ext\n",
    "    new_img_path = os.path.join(img_path, new_img_name_ext)\n",
    "\n",
    "    return new_img_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining a function to return the video filepath with a new filename.\n",
    "# If INPUT filepath is \"my_folder1/my_folder2/my_video.mp4\", OUTPUT filepath will be \"my_folder1/my_folder2/my_video_WITH_AGE.mp4\"\n",
    "\n",
    "def new_vid_name(org_vid_path):\n",
    "    vid_path, vid_name_ext = os.path.split(org_vid_path)\n",
    "    vid_name, vid_ext = os.path.splitext(vid_name_ext)\n",
    "\n",
    "    new_vid_name_ext = vid_name+\"_WITH_AGE\"+\".mp4\"\n",
    "    new_vid_path = os.path.join(vid_path, new_vid_name_ext)\n",
    "\n",
    "    return new_vid_path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Age Detection on Image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To detect age on an image, **provide the filepath to the image in the cell below**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Provide the image filepath as a string below.\n",
    "# For example: \"my_image.jpg\" or \"/content/drive/My Drive/my_folder/my_image.png\"\n",
    "\n",
    "my_image = \"Pawan.jpg\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'E:\\\\BlueBricks\\\\Age Estimation'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('46-65', 100.0)\n"
     ]
    }
   ],
   "source": [
    "# Reading the image from filepath provided above and passing it through the age clasification method defined above.\n",
    "\n",
    "img = cv2.imread(my_image)\n",
    "age_img = classify_age(img)\n",
    "\n",
    "# Saving the new generated image with a new name at the same location. \n",
    "try:\n",
    "    print(age_img)\n",
    "#     new_my_image = new_img_name(my_image)\n",
    "#     cv2.imwrite(new_my_image, age_img)\n",
    "#     print(f\"Saved to {new_my_image}\")\n",
    "except:\n",
    "    print(\"Error: Could not save image!\")\n",
    "\n",
    "#cv2.imshow(\"Age Detection on Image\", age_img)\n",
    "cv2.waitKey(0);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46-65\n",
      "100.0\n"
     ]
    }
   ],
   "source": [
    "age,conf = age_img\n",
    "\n",
    "print(age)\n",
    "print(conf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'python' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-40-45a3ce2a2cc7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__version__\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'python' is not defined"
     ]
    }
   ],
   "source": [
    "python.__version__\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Age Detection on Video"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To detect age on a video, either:\n",
    "1. use the code below for a **live webcam video**, or\n",
    "2. **provide the filepath to a video in the cell below**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Age Detection on Live Webcam Video"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Live webcam video will open in a new window. **Tap the \"Q\" key on the keyboard to EXIT.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accessing the webcam and passing the video frames through the age clasification method defined above.\n",
    "# Source 1: https://opencv-python-tutroals.readthedocs.io/en/latest/py_tutorials/py_gui/py_video_display/py_video_display.html\n",
    "# Source 2: https://www.learnopencv.com/read-write-and-display-a-video-using-opencv-cpp-python/\n",
    "\n",
    "# Creating a VideoCapture object.\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "# Checking if camera opened successfully.\n",
    "if (cap.isOpened() == False): \n",
    "    print(\"Unable to read camera feed!\")\n",
    "\n",
    "# Getting the video frame width and height.\n",
    "frame_width = int(cap.get(3))\n",
    "frame_height = int(cap.get(4))\n",
    "\n",
    "# Defining the codec and creating a VideoWriter object to save the output video in the current working directory.\n",
    "fourcc = cv2.VideoWriter_fourcc(*'MP4V')\n",
    "cur_time = datetime.fromtimestamp(time.time()).strftime('%Y%m%d%H%M%S')\n",
    "out = cv2.VideoWriter(f\"Webcam_{cur_time}_WITH_AGE.mp4\", fourcc, 18, (frame_width, frame_height))\n",
    "\n",
    "while(cap.isOpened()):\n",
    "    \n",
    "    # Grabbing each individual frame, frame-by-frame.\n",
    "    ret, frame = cap.read()\n",
    "    \n",
    "    if ret==True:\n",
    "        \n",
    "        # Running age detection on the grabbed frame.\n",
    "        age_img = classify_age(frame)\n",
    "        \n",
    "        # Saving frame to output video using the VideoWriter object defined above.\n",
    "        out.write(age_img)\n",
    "\n",
    "        # Displaying the frame with age detected.\n",
    "        cv2.imshow(\"Age Detection on Live Video\", age_img)\n",
    "        \n",
    "        # Exiting if \"Q\" key is pressed on the keyboard.\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "    \n",
    "    else:\n",
    "        break\n",
    "\n",
    "# Releasing the VideoCapture and VideoWriter objects, and closing the displayed frame.\n",
    "cap.release()\n",
    "out.release()\n",
    "cv2.destroyAllWindows()\n",
    "print(f\"Saved to Webcam_{cur_time}_WITH_AGE.mp4\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Age Detection on a Video File"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To detect age on a video, **provide the filepath to the video in the cell below**.\n",
    "\n",
    "The video will open in a new window. Wait for the code to finish running through the entire video, or **tap the \"Q\" key on the keyboard to EXIT in between**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Provide the video filepath as a string below\n",
    "# For example: \"my_video.mp4\" or \"/content/drive/My Drive/my_folder/my_video.mp4\"\n",
    "\n",
    "my_video = \"my_video.mp4\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading the video from filepath provided above and passing it through the age clasification method defined above.\n",
    "# Source 1: https://opencv-python-tutroals.readthedocs.io/en/latest/py_tutorials/py_gui/py_video_display/py_video_display.html\n",
    "# Source 2: https://www.learnopencv.com/read-write-and-display-a-video-using-opencv-cpp-python/\n",
    "\n",
    "# Creating a VideoCapture object.\n",
    "cap = cv2.VideoCapture(my_video)\n",
    "\n",
    "# Checking if video can be accessed successfully.\n",
    "if (cap.isOpened() == False): \n",
    "    print(\"Unable to read video!\")\n",
    "\n",
    "# Getting the video frame width and height.\n",
    "frame_width = int(cap.get(3))\n",
    "frame_height = int(cap.get(4))\n",
    "\n",
    "# Defining the codec and creating a VideoWriter object to save the output video at the same location.\n",
    "fourcc = cv2.VideoWriter_fourcc(*'MP4V')\n",
    "new_my_video = new_vid_name(my_video)\n",
    "out = cv2.VideoWriter(new_my_video, fourcc, 18, (frame_width, frame_height))\n",
    "\n",
    "while(cap.isOpened()):\n",
    "    \n",
    "    # Grabbing each individual frame, frame-by-frame.\n",
    "    ret, frame = cap.read()\n",
    "    \n",
    "    if ret==True:\n",
    "        \n",
    "        # Running age detection on the grabbed frame.\n",
    "        age_img = classify_age(frame)\n",
    "        \n",
    "        # Saving frame to output video using the VideoWriter object defined above.\n",
    "        out.write(age_img)\n",
    "        \n",
    "        # Displaying the frame with age detected.\n",
    "        cv2.imshow(\"Age Detection on Video\", age_img)\n",
    "        \n",
    "        # Exiting if \"Q\" key is pressed on the keyboard.\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "    else:\n",
    "        break\n",
    "\n",
    "# Releasing the VideoCapture and VideoWriter objects, and closing the displayed frame.\n",
    "cap.release()\n",
    "out.release()\n",
    "cv2.destroyAllWindows()\n",
    "print(f\"Saved to {new_my_video}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "cap = cv2.VideoCapture('HOUSE TOUR Broadbeach Waters Gold Coast Prize Home_480p.mp4')\n",
    "count = 0\n",
    "\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "\n",
    "    if ret:\n",
    "        # Display the resulting frame\n",
    "        cv2.imshow('Frame', frame)\n",
    "            \n",
    "        count += 30 # i.e. at 30 fps, this advances one second\n",
    "        cap.set(1, count)\n",
    "        \n",
    "        # Press Q on keyboard to  exit\n",
    "        if cv2.waitKey(25) & 0xFF == ord('q'):\n",
    "            break\n",
    "    else:\n",
    "        print('No frame to read')\n",
    "        cap.release()\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
